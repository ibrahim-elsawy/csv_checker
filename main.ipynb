{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import os\n",
    "os.add_dll_directory(r'C:\\Users\\ZZ01KD865\\Documents\\projects\\csv_checker\\env\\Lib\\site-packages\\clidriver\\bin') \n",
    "import ibm_db\n",
    "import json\n",
    "from ftplib import FTP\n",
    "import pandas as pd\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv read successfully.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Specify the directory containing the zip files\n",
    "directory = './compress/'\n",
    "\n",
    "# List to store DataFrames from CSV files\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    # Check if the file is a zip file\n",
    "    if filename.endswith('.zip'):\n",
    "        # Open the zip file\n",
    "        with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "            # Iterate over each file in the zip\n",
    "            for file_info in zip_ref.infolist():\n",
    "                # Check if the file is a CSV\n",
    "                if file_info.filename.endswith('.csv'):\n",
    "                    # Extract the file contents into memory\n",
    "                    with zip_ref.open(file_info) as csv_file:\n",
    "                        # Read the CSV data into a DataFrame\n",
    "                        df = pd.read_csv(BytesIO(csv_file.read()))\n",
    "                        # Append the DataFrame to the list\n",
    "                        dataframes.append(df)\n",
    "                        print(f\"{file_info.filename} read successfully.\")\n",
    "\n",
    "# Now you have a list of DataFrames from all the CSV files\n",
    "# You can concatenate them if needed\n",
    "result_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_file_size(file_path):\n",
    "    try:\n",
    "        # Get the size of the file in bytes\n",
    "        file_size_bytes = os.path.getsize(file_path)\n",
    "\n",
    "        # Convert bytes to kilobytes or megabytes if needed\n",
    "        file_size_kb = file_size_bytes / 1024  # Convert bytes to kilobytes\n",
    "        file_size_mb = file_size_kb / 1024     # Convert kilobytes to megabytes\n",
    "\n",
    "        return file_size_bytes, file_size_kb, file_size_mb\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting file size: {e}\")\n",
    "        return None\n",
    "    \n",
    "# def get_file_size_ftp(ftp, file_path):\n",
    "#     # Get the size of the file\n",
    "#     file_size = ftp.size(file_path)\n",
    "#     # Convert the file size to MB\n",
    "#     file_size_mb = file_size / (1024 * 1024)\n",
    "#     return \"{:.2f}\".format(file_size_mb)\n",
    "\n",
    "\n",
    "# def get_file_encoding(file_path):\n",
    "#     try:\n",
    "#         with open(file_path, 'rb') as f:\n",
    "#             # Read a chunk of the file to detect the encoding\n",
    "#             rawdata = f.read()\n",
    "#             result = chardet.detect(rawdata)\n",
    "#             return result['encoding']\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error detecting file encoding: {e}\")\n",
    "#         return None\n",
    "\n",
    "def get_file_size(df):\n",
    "    # Get memory usage of each column in bytes\n",
    "    memory_usage_bytes = df.memory_usage(deep=True).sum()\n",
    "    # Convert bytes to megabytes (MB)\n",
    "    memory_usage_mb = memory_usage_bytes / (1024 * 1024)\n",
    "    return memory_usage_mb\n",
    "\n",
    "\n",
    "def get_file_encoding(bytes_io):\n",
    "    try:\n",
    "        bytes_io.seek(0)\n",
    "        rawdata = bytes_io.read()\n",
    "        result = chardet.detect(rawdata)\n",
    "        return result['encoding']\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting file encoding: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_filename(file_path):\n",
    "    return os.path.basename(file_path)\n",
    "\n",
    "\n",
    "def get_csv_metadata(file_path, df):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        column_names = df.columns.tolist()\n",
    "    \n",
    "        data_types = df.dtypes.tolist()\n",
    "        \n",
    "        # summary_statistics = df.describe()\n",
    "        \n",
    "        num_rows, num_columns = df.shape\n",
    "        metadata = {\n",
    "            # 'column_names': column_names,\n",
    "            # 'data_types': data_types,\n",
    "            # 'summary_statistics': summary_statistics,\n",
    "            'filename': [file_path,],\n",
    "            # 'encoding':[get_file_encoding(bytes_io),],\n",
    "            'file_size':[get_file_size(df),],\n",
    "            'num_rows': [num_rows,],\n",
    "            'num_columns': [num_columns,]\n",
    "            \n",
    "        }\n",
    "        return pd.DataFrame(metadata)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_object(file_name='config.json'): \n",
    "\twith open('config.json', 'r') as file: \n",
    "\t\tconfig = json.load(file)\n",
    "\treturn config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_df_to_db2(df, table_name):\n",
    "    config = get_config_object()\n",
    "    # Connection parameters\n",
    "    database_name = config['database']['database_name']\n",
    "    hostname = config['database']['host']\n",
    "    port = config['database']['port']\n",
    "    protocol = \"TCPIP\"\n",
    "    user = config['database']['username']\n",
    "    password = config['database']['password']\n",
    "\n",
    "    # Connection string\n",
    "    dsn = (\n",
    "        \"DRIVER={{IBM DB2 ODBC DRIVER}};\"\n",
    "        \"DATABASE={0};\"\n",
    "        \"HOSTNAME={1};\"\n",
    "        \"PORT={2};\"\n",
    "        \"PROTOCOL={3};\"\n",
    "        \"UID={4};\"\n",
    "        \"PWD={5};\"\n",
    "    ).format(database_name, hostname, port, protocol, user, password)\n",
    "\n",
    "    # Establish the database connection\n",
    "    conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "\n",
    "    # Check if the connection is successful\n",
    "    if conn:\n",
    "        print(\"Connected to the database\")\n",
    "\n",
    "        # Insert DataFrame into DB2 table\n",
    "        df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "        # Close the connection\n",
    "        ibm_db.close(conn)\n",
    "        print(\"Connection closed\")\n",
    "    else:\n",
    "        print(\"Failed to connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 11001] getaddrinfo failed\n"
     ]
    }
   ],
   "source": [
    "def get_df_from_zip(file_bytes):\n",
    "    dataframes = []\n",
    "    file_bytes.seek(0)\n",
    "    with zipfile.ZipFile(file_bytes,'r') as zip_ref:\n",
    "        # Iterate over each file in the zip\n",
    "        for file_info in zip_ref.infolist():\n",
    "                # Check if the file is a CSV\n",
    "                if file_info.filename.endswith('.csv'):\n",
    "                    # Extract the file contents into memory\n",
    "                    with zip_ref.open(file_info) as csv_file:\n",
    "                        # Read the CSV data into a DataFrame\n",
    "                        df = pd.read_csv(BytesIO(csv_file.read()))\n",
    "                        # Append the DataFrame to the list\n",
    "                        dataframes.append(df)\n",
    "        return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "def read_csv_from_ftp_and_delete(config_obj):\n",
    "    try:\n",
    "        host = config_obj['ftp']['host']\n",
    "        username = config_obj['ftp']['username']\n",
    "        password = config_obj['ftp']['password']\n",
    "        directory = config_obj['ftp']['directory']\n",
    "        df_data_list = []\n",
    "        df_meta_list = []\n",
    "        # Connect to the FTP server\n",
    "        ftp = FTP(host)\n",
    "        ftp.login(username, password)\n",
    "        # Change to the specified directory\n",
    "\n",
    "        ftp.cwd(directory)\n",
    "\n",
    "        # List all files in the directory\n",
    "        file_list = ftp.nlst()\n",
    "\n",
    "        for filename in file_list:\n",
    "            # Read the CSV file into a BytesIO object\n",
    "            zip_data = io.BytesIO()\n",
    "            ftp.retrbinary(f'RETR {filename}', zip_data.write)\n",
    "            zip_data.seek(0)  # Reset the file pointer to the beginning\n",
    "\n",
    "            #convert zip file to DataFrame\n",
    "            # Read the CSV data from BytesIO into a pandas DataFrame\n",
    "            df_data = get_df_from_zip(zip_data)\n",
    "\n",
    "            # df_data = pd.read_csv(csv_data)\n",
    "            # df_meta = get_csv_metadata(ftp,filename,csv_data)\n",
    "            df_meta = get_csv_metadata(ftp,filename,df_data)\n",
    "            df_data_list.append(df_data)\n",
    "            df_meta_list.append(df_meta)\n",
    "\n",
    "            # Delete the file on the remote machine\n",
    "            ftp.delete(filename)\n",
    "            print(f\"File '{filename}' deleted successfully.\")\n",
    "\n",
    "        # Close the FTP connection\n",
    "        ftp.quit()\n",
    "        return df_data_list, df_meta_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = sys.argv\n",
    "    try: \n",
    "        config_path = args[1]\n",
    "        config_obj = get_config_object(config_path)\n",
    "        # get meta df and data df\n",
    "        df_data, df_meta = read_csv_from_ftp_and_delete(config_obj)\n",
    "        # store df_data\n",
    "        store_df_to_db2(df_data,config_obj['database']['meta_table'])\n",
    "        # store df_meta\n",
    "        store_df_to_db2(df_meta, config_obj['database']['data_table'])\n",
    "    except:\n",
    "        print(\"config file doesn't exsit\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
